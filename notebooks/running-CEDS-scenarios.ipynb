{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running CEDS Scenarios\n",
    "\n",
    "In this notebook we document how to process and run data from the CEDS database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from os import listdir\n",
    "from os.path import join, dirname\n",
    "from pprint import pprint\n",
    "from copy import deepcopy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyam\n",
    "from pyam.utils import LONG_IDX\n",
    "import pint\n",
    "from pint.pandas_interface import PintArray\n",
    "from pint.errors import DimensionalityError\n",
    "\n",
    "import pymagicc\n",
    "from pymagicc.io import MAGICCData\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('bmh') \n",
    "\n",
    "import expectexception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DATA_PATH = join(\"..\", \"tests\", \"test_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in a CEDS csv\n",
    "\n",
    "To read in CEDS csv's, we make use of the `pyam` library which is specifically designed for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ceds_csv(file_to_read):\n",
    "    return pyam.IamDataFrame(\n",
    "        data=file_to_read,\n",
    "        encoding=\"utf-8\"\n",
    "    )\n",
    "\n",
    "ceds_pyam_df = read_ceds_csv(join(TEST_DATA_PATH, \"ceds-format-example-2.csv\"))\n",
    "ceds_pyam_df  # this just shows the type of ceds_pyam_df\n",
    "ceds_pyam_df.data.head()  # this returns the head of the underlying DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Super brief intro to pyam\n",
    "\n",
    "The `pyam` library provides some very natural ways of filtering their DataFrames. These are detailed in [their tutorial](https://github.com/IAMconsortium/pyam/blob/master/tutorial/pyam_first_steps.ipynb). Here we use them to help convert IAM data into the emissions variables, regions and units used by openscm and MAGICC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this only gets first level emissions and \n",
    "# World values\n",
    "tdf = ceds_pyam_df.filter(\n",
    "    level=1,\n",
    "    region=\"World\",\n",
    ")\n",
    "tdf.variables()\n",
    "tdf.regions()\n",
    "tdf.data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking an `IamDataFrame`\n",
    "\n",
    "It is very easy to check that the sum of a given variable's sub-categories is equal to its declared total and that the sum of regions gives the world total.\n",
    "\n",
    "We show how in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show check_internal_consistency method here once PR into pyam\n",
    "# is accepted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting CEDS data to openscm data\n",
    "\n",
    "In the Python implementation of `openscm`, we want to work with `IamDataFrame`'s for as long as possible thanks to their useful aggregating, filtering and other methods. \n",
    "\n",
    "Hence all we do to convert from CEDS data to openscm is tweak the underlying `DataFrame`.\n",
    "\n",
    "We start by aggregating the data from the CEDS csv into `openscm` relevant categories. \n",
    "\n",
    "We also strip 'equiv' and '-' from units so that pint can read the units and subsequently from variable names for consistency. Yes:\n",
    "\n",
    "1. it looks odd to have HFC in units of 'CO2' but it's hopefully fairly clear that this is an equivalence unit\n",
    "1. changing from IAM units and names in this way is annoying but pint is worth it so we make the switch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before we do anything, we add a metadata attribute to pyam.IamDataFrame\n",
    "# which we can use as a temporary measure in this notebook\n",
    "pyam.IamDataFrame.metadata = dict()\n",
    "\n",
    "def convert_pyam_df_to_openscm_df(pyam_df):\n",
    "    TMP_INDEX = ['model', 'scenario', 'region', 'year', 'unit']\n",
    "    \n",
    "    ceds_openscm_var_mapping = {\n",
    "        \"Aircraft\": [\"Aircraft\"],\n",
    "        \"International Shipping\": [\"International Shipping\"],\n",
    "        \"AFOLULUC\": [\"Agricultural Waste Burning\", \"Agriculture\", \n",
    "                     \"Forest Burning\", \"Grassland Burning\", \n",
    "                     \"Peat Burning\", \"Aggregate - Agriculture and LUC\"],\n",
    "        \"Fossil\": [\"Energy Sector\", \"Industrial Sector\", \n",
    "                   \"Residential Commercial Other\", \n",
    "                   \"Solvents Production and Application\", \n",
    "                   \"Transportation Sector\", \"Waste\"]\n",
    "    }\n",
    "    \n",
    "    openscm_df = pyam.IamDataFrame(data=pyam_df.data.copy())\n",
    "    \n",
    "    output_df = openscm_df.filter(level=1,).data\n",
    "    sectoral_df = openscm_df.filter(\n",
    "        level='1-', \n",
    "        keep=False\n",
    "    )\n",
    "    \n",
    "    handled_vars = []\n",
    "    metadata = {}\n",
    "    var_dfs = []\n",
    "    for variable in sectoral_df.variables():\n",
    "        var_bits = variable.split(\"|\")\n",
    "        base_var = \"|\".join(var_bits[:2])\n",
    "        extension = \"|\".join(var_bits[2:3])\n",
    "        assert \"|\" not in extension, \"Handling more than one level deep not ready yet\"\n",
    "        \n",
    "        for category, suffixes in ceds_openscm_var_mapping.items():\n",
    "            if extension not in suffixes:\n",
    "                continue\n",
    "                \n",
    "            openscm_var = \"{}|{}\".format(\n",
    "                \"|\".join(variable.split(\"|\")[:-1]),\n",
    "                category,\n",
    "            )\n",
    "            \n",
    "            if openscm_var in handled_vars:\n",
    "                continue\n",
    "            handled_vars.append(openscm_var)\n",
    "            \n",
    "            contrib_vars = [\"{}|{}\".format(base_var, s) for s in suffixes]\n",
    "\n",
    "            var_cat_df = sectoral_df.data[sectoral_df.data.variable.isin(contrib_vars)]\n",
    "            var_cat_df = pd.DataFrame(var_cat_df.groupby(TMP_INDEX).sum()['value'])\n",
    "            var_cat_df = pd.concat([var_cat_df], keys=[openscm_var], names=['variable'])\n",
    "            \n",
    "            var_dfs.append(var_cat_df.reset_index())\n",
    "\n",
    "            metadata[openscm_var] = \"Sum of {}\".format(\", \".join(contrib_vars))\n",
    "    \n",
    "    output_df = pd.concat([output_df] + var_dfs, sort=False)\n",
    "    output_df.unit = output_df.unit.str.replace(\"-equiv\", \"\").str.replace(\"-\", \"\")\n",
    "    output_df.variable = output_df.variable.str.replace(\"-\", \"\")\n",
    "    \n",
    "    output_df = pyam.IamDataFrame(data=output_df)\n",
    "    \n",
    "    output_df.metadata = pyam_df.metadata\n",
    "    output_df.metadata.update(metadata)\n",
    "    \n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openscm_df = convert_pyam_df_to_openscm_df(ceds_pyam_df)\n",
    "\n",
    "# check out metadata with this\n",
    "print([\n",
    "    \"{}: {}\".format(k,openscm_df.metadata[k])\n",
    "    for k in list(openscm_df.metadata)[:3]\n",
    "])\n",
    "\n",
    "# check out table with this\n",
    "openscm_df.head()\n",
    "\n",
    "# check regions with this\n",
    "openscm_df.regions()\n",
    "\n",
    "# check out variables with this\n",
    "openscm_df.variables()[:10]\n",
    "\n",
    "# check out units with this\n",
    "openscm_df.data.unit.unique()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting units\n",
    "\n",
    "In the next part we start to do unit conversions. Before moving on, we briefly explain how we do this.\n",
    "\n",
    "We load units with Pint like so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ureg = pint.UnitRegistry()  # start a unit repository using the default variables\n",
    "ureg.load_definitions('emissions_units.txt')  # load emissions units too\n",
    "ureg._contexts  # show us which contexts we have available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some variables with units\n",
    "a = 1*ureg.C\n",
    "b = 1*ureg.CO2\n",
    "c = 3*ureg.N2O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# they carry units with them\n",
    "a\n",
    "b\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can convert them to base units or to each other\n",
    "b.to_base_units()\n",
    "b.to('C')\n",
    "c.to('N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# operations are units aware\n",
    "a + b\n",
    "a * b\n",
    "(a * b).to_base_units()\n",
    "a / b\n",
    "(a / b).to_base_units()\n",
    "a - b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with a context, we can use metric conversions to \n",
    "# do our conversions\n",
    "# e.g. AR4GWP12 which is a made up metric where 1C = 20N\n",
    "# hence 1 CO2 = 12/44 C = 12/44*20 N = 12/44*20*14/44 N2O\n",
    "\n",
    "with ureg.context('AR4GWP12'):\n",
    "    b\n",
    "    b.to('N2O')\n",
    "    12/44*20*14/44\n",
    "    a.to('N') + c  # I am not sure why you need to force the conversion of `a` first..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%expect_exception DimensionalityError\n",
    "# without a context to tell us about metrics, if \n",
    "# we try to do an invalid conversion, a \n",
    "# DimensionalityError will be thrown\n",
    "b.to('N2O')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Units in DataFrames\n",
    "\n",
    "Pint comes with accesors for pandas dataframes. This is super useful but also very young so can be a bit fiddly. \n",
    "\n",
    "For example, below we show how to convert a variable to a given set of units whilst maintaining index etc., something which the pint accessor can't do (yet).\n",
    "\n",
    "We will use this function to convert our data table to MAGICC units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_variable_units(pyam_df, variable, target_units):\n",
    "    output_df = pyam.IamDataFrame(pyam_df.data.copy())\n",
    "    \n",
    "    var_df = pyam_df.filter(variable=variable).data.copy()\n",
    "    rest_df = pyam_df.filter(variable=variable, keep=False).data.copy()\n",
    "    \n",
    "    var_df = var_df.set_index(LONG_IDX).unstack([\"variable\", \"unit\"])\n",
    "    var_df = var_df.pint.quantify(ureg, level=-1)\n",
    "    \n",
    "    for col in var_df:\n",
    "        var_df[col] = var_df[col].pint.to(target_units)\n",
    "    # annoying that pint dequantify destroys index\n",
    "    old_index = var_df.index\n",
    "    old_columns = var_df.columns\n",
    "    var_df = var_df.pint.dequantify()\n",
    "    var_df.index = old_index\n",
    "    var_df.columns.names = old_columns.names + ['unit']\n",
    "\n",
    "    var_df = var_df.stack().stack().reset_index()\n",
    "\n",
    "    output_df = pyam.IamDataFrame(pd.concat([var_df, rest_df], sort=False))\n",
    "    output_df.metadata = pyam_df.metadata\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original DataFrame\")\n",
    "print(\"------------------\")\n",
    "original_df = ceds_pyam_df.filter(\n",
    "    variable=\"Emissions|CO2*\"\n",
    ")\n",
    "original_df.head()\n",
    "\n",
    "print(\"\")\n",
    "print(\"DataFrame with converted units\")\n",
    "print(\"------------------------------\")\n",
    "converted_df = convert_variable_units(ceds_pyam_df, \"Emissions|CO2\",\"Gt C/yr\").filter(\n",
    "    variable=\"Emissions|CO2*\"\n",
    ")\n",
    "converted_df.head()\n",
    "\n",
    "print(\"\")\n",
    "print(\"Ratio of first line values\")\n",
    "print(\"{}\".format(\n",
    "    original_df.data.value.iloc[0] \n",
    "    / converted_df.data.value.iloc[0]\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting openscm data to MAGICC data\n",
    "\n",
    "Here we show how to then convert an openscm data table to MAGICC data. MAGICC is a somewhat special beast so there's a few transformations we have to do:\n",
    "\n",
    "- convert openscm variables to MAGICC variables and regions\n",
    "    - conventionally we make everything uppercase to remind ourselves that these variables and regions will be used in FORTRAN in the end (which is case insensitive) but this might be another annoying mapping so we might take this out in future (as we're not going backwards right now, we leave it)\n",
    "- convert everything to MAGICC's units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emissions_species(variable):\n",
    "    exceptions = [\"HCFC141B\", \"HCFC142B\"]\n",
    "    variable = variable.replace(\"_EMIS\", \"\")\n",
    "    if variable in exceptions:\n",
    "        return variable\n",
    "    elif variable.endswith((\"I\", \"B\")):\n",
    "        return variable[:-1]\n",
    "    elif variable.endswith((\"AIR\", \"SHIP\")):\n",
    "        return variable.replace(\"AIR\", \"\").replace(\"SHIP\", \"\")\n",
    "    else:\n",
    "        return variable\n",
    "    \n",
    "def convert_openscm_to_magicc_variable(openscm_variable):\n",
    "    category_codes = {\n",
    "        \"Aircraft\": \"AIR\",\n",
    "        \"International Shipping\": \"SHIP\",\n",
    "        \"AFOLULUC\": \"B\",\n",
    "        \"Fossil\": \"I\",\n",
    "    }\n",
    "    \n",
    "    special_cases = {\n",
    "        \"VOC\": \"NMVOC\",\n",
    "        \"Sulfur\": \"SOX\",\n",
    "        \"HFC4310mee\": \"HFC4310\",\n",
    "    }\n",
    "    \n",
    "    # Improvement: do this with regexp\n",
    "    species = openscm_variable.split(\"|\")[1]\n",
    "    if species in special_cases:\n",
    "        species = special_cases[species]\n",
    "        \n",
    "    try:\n",
    "        category = openscm_variable.split(\"|\")[2]\n",
    "        category_code = category_codes[category]\n",
    "    except IndexError:\n",
    "        category_code = \"\"\n",
    "    \n",
    "    return \"{}{}_EMIS\".format(species.upper(), category_code)\n",
    "    \n",
    "def convert_openscm_to_magicc_df(openscm_df):\n",
    "    magicc_df = pyam.IamDataFrame(data=openscm_df.data.copy())\n",
    "    magicc_df.metadata = deepcopy(openscm_df.metadata)\n",
    "\n",
    "    magicc_df.data.variable = magicc_df.data.variable.apply(convert_openscm_to_magicc_variable)\n",
    "    magicc_df.data.region = magicc_df.data.region.str.upper()\n",
    "    magicc_df.data = magicc_df.filter(variable=\"HFC_EMIS\", keep=False).data\n",
    "\n",
    "    for variable in magicc_df.variables():\n",
    "        magicc_unit_df = pymagicc.definitions.emms_units\n",
    "        magicc_units = magicc_unit_df[\n",
    "            magicc_unit_df[\"MAGICC variable\"] == get_emissions_species(variable)\n",
    "        ][\"emissions units\"].values\n",
    "        assert len(magicc_units) == 1, \"{} {}\".format(variable, magicc_units)\n",
    "        magicc_units = magicc_units[0]\n",
    "\n",
    "        magicc_df = convert_variable_units(magicc_df, variable, magicc_units)\n",
    "    \n",
    "    return magicc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magicc_df = convert_openscm_to_magicc_df(openscm_df)\n",
    "\n",
    "# have a look at some conversions\n",
    "openscm_df.data[openscm_df.data.variable.str.contains(\"NH3\\\\|Fossil\")].sort_values([\"region\", \"year\"]).head()\n",
    "magicc_df.data[magicc_df.data.variable.str.contains(\"NH3I\")].sort_values([\"region\", \"year\"]).head()\n",
    "\n",
    "openscm_df.data[openscm_df.data.variable.str.contains(\"CO2\\\\|AFOL\")].sort_values([\"region\", \"year\"]).head()\n",
    "magicc_df.data[magicc_df.data.variable.str.contains(\"CO2B\")].sort_values([\"region\", \"year\"]).head()\n",
    "\n",
    "# check out metadata with this\n",
    "print([\n",
    "    \"{}: {}\".format(k,magicc_df.metadata[k])\n",
    "    for k in list(magicc_df.metadata)[:3]\n",
    "])\n",
    "\n",
    "# check out table with this\n",
    "magicc_df.head()\n",
    "\n",
    "# check out variables with this\n",
    "magicc_df.variables()[:10]\n",
    "\n",
    "# check out units with this\n",
    "magicc_df.data.unit.unique()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supplementing CEDS data\n",
    "\n",
    "Before we go into writing scenario files, we supplement the CEDS data. The only variable we have to do this for is C6F14 as it is required to run MAGICC6. The rest are purely for interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2f6_df = magicc_df.filter(variable=\"*C2F6*\").data.copy()\n",
    "c6f14_df = c2f6_df.copy()\n",
    "c6f14_df.unit = \"C6F14 * kt / yr\"\n",
    "c6f14_df.variable = \"C6F14_EMIS\"\n",
    "\n",
    "# hardcoded as MAGICC7 inputs not yet public\n",
    "c6f14_2015_value = 0.3500\n",
    "sf = c6f14_2015_value / c2f6_df.value[c2f6_df.year == 2015][0]\n",
    "c6f14_df.value *= sf\n",
    "\n",
    "# should probably add metadata here...\n",
    "magicc_df.data = pd.concat([magicc_df.data, c6f14_df], sort=False)\n",
    "\n",
    "np.testing.assert_allclose(c6f14_df.value / c2f6_df.value, sf)\n",
    "\n",
    "c6f14_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magicc_df.filter(\n",
    "    variable=[\"*C2F6*\", \"*C6F14*\"]\n",
    ").line_plot(figsize=(16, 9));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing MAGICC scenario files\n",
    "\n",
    "Once we have our dataframe, we lastly want to cut it to either write SCEN or SCEN7 files.\n",
    "\n",
    "### Converting to SCEN7 format\n",
    "\n",
    "Firstly we show how to get things into a SCEN7 format. The major steps are:\n",
    "\n",
    "- create a BUNKERS region from aviation and shipping emissions\n",
    "- make sure we only provide the regional/sectoral breakdown for emissions if we have them, not the totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bunkers_to_magicc_variable(bunker_variable):\n",
    "    return bunker_variable.replace(\"SHIP\", \"I\").replace(\"AIR\", \"I\")\n",
    "\n",
    "def get_bunkers_df_from_magicc_df(magicc_df):\n",
    "    ship_df = magicc_df.filter(variable=\"*SHIP*\").data\n",
    "    ship_df.variable = ship_df.variable.apply(convert_bunkers_to_magicc_variable)\n",
    "    ship_df.region = \"BUNKERS\"\n",
    "    ship_df.set_index(LONG_IDX, inplace=True)\n",
    "    \n",
    "    air_df = magicc_df.filter(variable=\"*AIR*\").data\n",
    "    air_df.variable = air_df.variable.apply(convert_bunkers_to_magicc_variable)\n",
    "    air_df.region = \"BUNKERS\"\n",
    "    air_df.set_index(LONG_IDX, inplace=True)\n",
    "\n",
    "    bunkers_df = ship_df + air_df\n",
    "    bunkers_df.reset_index(inplace=True)\n",
    "    \n",
    "    return bunkers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def magicc_df_to_scen7_df(magicc_df):\n",
    "    scen7_df = magicc_df.filter(\n",
    "        variable=[\"*SHIP*\", \"*AIR*\"], \n",
    "        keep=False\n",
    "    )\n",
    "    # strip out all the variables with breakdown\n",
    "    # data available\n",
    "    for variable in scen7_df.variables():\n",
    "        if variable.endswith((\"I_EMIS\", \"B_EMIS\")):\n",
    "            continue\n",
    "\n",
    "        if variable.replace(\"_EMIS\", \"I_EMIS\") in scen7_df.variables().tolist():\n",
    "            scen7_df = scen7_df.filter(\n",
    "                variable=variable, \n",
    "                keep=False\n",
    "            )\n",
    "    \n",
    "    # to dicuss with Malte, should we do this \n",
    "    # given I don't think it matters:\n",
    "    # - add in N2O breakdown\n",
    "    # - add in CO2B breakdown\n",
    "    \n",
    "    scen7_df = scen7_df.data\n",
    "    bunkers_df = get_bunkers_df_from_magicc_df(magicc_df)\n",
    "    \n",
    "    scen7_df = pd.concat([scen7_df, bunkers_df], sort=False)\n",
    "    scen7_df = pyam.IamDataFrame(data=scen7_df)\n",
    "    scen7_df.metadata = magicc_df.metadata\n",
    "    \n",
    "    return scen7_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scen7_df = magicc_df_to_scen7_df(magicc_df)\n",
    "\n",
    "# check out metadata with this\n",
    "print([\n",
    "    \"{}: {}\".format(k,scen7_df.metadata[k])\n",
    "    for k in list(scen7_df.metadata)[:3]\n",
    "])\n",
    "\n",
    "# check out table with this\n",
    "scen7_df.head()\n",
    "\n",
    "# check out variables with this\n",
    "scen7_df.variables()[:10]\n",
    "\n",
    "# check out regions with this\n",
    "scen7_df.regions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping an `IamDataFrame`\n",
    "\n",
    "Here we show how to reshape an `IamDataFrame` to get it into the format expected by `openscm` so we can then write files with the data in it.\n",
    "\n",
    "We also tidy up the units so they look a bit nicer.\n",
    "\n",
    "Note: we normally want to take this step last, after we have done all our aggregation etc., as it means that we no longer have an `IamDataFrame` and can't use all the helpful tools it provides any more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tidy_units(input_unit):\n",
    "    species, mass_per_time = input_unit.split(\"*\")\n",
    "    mass, time = mass_per_time.split(\"/\")\n",
    "    \n",
    "    mass = mass.replace(\"gigametric_ton\", \"Gt\")\n",
    "    mass = mass.replace(\"megametric_ton\", \"Mt\")\n",
    "    mass = mass.replace(\"kilometric_ton\", \"kt\")\n",
    "    mass = mass.replace(\"metric_ton\", \"tt\")\n",
    "    \n",
    "    return \"{} {} / {}\".format(\n",
    "        mass.strip(), \n",
    "        species.strip(), \n",
    "        time.strip()\n",
    "    )\n",
    "\n",
    "def reshape_magicc_df_to_pymagicc_df(magicc_df):\n",
    "    pymagicc_df = magicc_df.pivot_table(\n",
    "        index=['year'], \n",
    "        columns=['model', 'scenario', 'variable', 'unit', 'region'], \n",
    "        values='value',\n",
    "        aggfunc='sum',\n",
    "    )\n",
    "    \n",
    "    years = pymagicc_df.index\n",
    "    if (years % 1 == 0).all() :\n",
    "        pymagicc_df.index = years.astype(int)\n",
    "    pymagicc_df.index.name = \"YEAR\"\n",
    "    \n",
    "    models = pymagicc_df.columns.get_level_values(\"model\")\n",
    "    scenarios = pymagicc_df.columns.get_level_values(\"scenario\")\n",
    "    regions = pymagicc_df.columns.get_level_values(\"region\")\n",
    "    variables = pymagicc_df.columns.get_level_values(\"variable\")\n",
    "    units = pymagicc_df.columns.get_level_values(\"unit\")\n",
    "    units = [tidy_units(u) for u in units]\n",
    "    todos = [\"SET\"] * len(units)\n",
    "    \n",
    "    pymagicc_df.columns = pd.MultiIndex.from_arrays(\n",
    "        [models, scenarios, variables, todos, units, regions],\n",
    "        names=(\"MODEL\", \"SCENARIO\", \"VARIABLE\", \"TODO\", \"UNITS\", \"REGION\"),\n",
    "    )\n",
    "    \n",
    "    pymagicc_out = MAGICCData\n",
    "    pymagicc_out.df = pymagicc_df\n",
    "    pymagicc_out.metadata = magicc_df.metadata\n",
    "    \n",
    "    return pymagicc_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pymagicc_df = reshape_magicc_df_to_pymagicc_df(scen7_df)\n",
    "pymagicc_df.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing SCEN7 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, df in pymagicc_df.df.groupby(level=[\"MODEL\", \"SCENARIO\"], axis=1):        \n",
    "    fn = \"{}_{}\".format(*label).replace(\" \", \"-\").replace(\".\", \"-\") + \".SCEN7\"\n",
    "\n",
    "    df.columns = df.columns.droplevel(\"MODEL\").droplevel(\"SCENARIO\")\n",
    "    \n",
    "    writer = MAGICCData()\n",
    "    writer.df = df\n",
    "    writer.metadata = {\n",
    "        \"header\": \"Emissions scenario for {}-{}\\n\\n\".format(*label)\n",
    "    }\n",
    "    writer.write(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting to SCEN format\n",
    "\n",
    "The major thing here is to ensure that we only return the variables MAGICC6 uses. Otherwise very similar to SCEN7 files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def magicc_df_to_scen_df(magicc_df, world_only=True):\n",
    "    if not world_only:\n",
    "        raise NotImplementedError(\"Neccesary checks not yet included e.g. no breakdown for HFC emissions\")\n",
    "\n",
    "    scen_df = magicc_df.filter(\n",
    "        variable=[\"*SHIP*\", \"*AIR*\"],\n",
    "        keep=False\n",
    "    )\n",
    "    \n",
    "    scen_df = scen_df.data\n",
    "    bunkers_df = get_bunkers_df_from_magicc_df(magicc_df)\n",
    "    \n",
    "    scen_df = pd.concat([scen_df, bunkers_df], sort=False)\n",
    "    \n",
    "    scen_df = pyam.IamDataFrame(data=scen_df)\n",
    "    if world_only:\n",
    "        scen_df = scen_df.filter(\n",
    "            region=\"WORLD\"\n",
    "        )\n",
    "    \n",
    "    scen_emis = [\n",
    "        v + \"_EMIS\" \n",
    "        for v in pymagicc.definitions.scen_emms_code_1\n",
    "    ]\n",
    "    output_df = scen_df.filter(variable=scen_emis)\n",
    "    output_df.metadata = magicc_df.metadata\n",
    "    \n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scen_df = magicc_df_to_scen_df(magicc_df)\n",
    "\n",
    "# check out metadata with this\n",
    "print([\n",
    "    \"{}: {}\".format(k,scen_df.metadata[k])\n",
    "    for k in list(scen_df.metadata)[:3]\n",
    "])\n",
    "\n",
    "# check out table with this\n",
    "scen_df.head()\n",
    "\n",
    "# check out variables with this\n",
    "scen_df.variables()[:10]\n",
    "\n",
    "# check out regions with this\n",
    "scen_df.regions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pymagicc_df = reshape_magicc_df_to_pymagicc_df(scen_df)\n",
    "pymagicc_df.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing SCEN files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, df in pymagicc_df.df.groupby(level=[\"MODEL\", \"SCENARIO\"], axis=1):        \n",
    "    fn = \"{}_{}\".format(*label).replace(\" \", \"-\").replace(\".\", \"-\") + \".SCEN\"\n",
    "\n",
    "    df.columns = df.columns.droplevel(\"MODEL\").droplevel(\"SCENARIO\")\n",
    "\n",
    "    writer = MAGICCData()\n",
    "    writer.df = df\n",
    "    writer.metadata = {\n",
    "        \"header\": \"required for some reason\\n\\n\"\n",
    "    }\n",
    "    writer.write(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a SCEN file we just wrote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = pymagicc.read_scen_file(\"MESSAGEix-GLOBIOM-PostParis-4-0_zero2070_5_3_nonco2_200.SCEN\")\n",
    "scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pymagicc.run(scenario)\n",
    "results['CO2I_EMIS'].plot(figsize=(16, 9))\n",
    "results['SURFACE_TEMP'].plot(figsize=(16, 9));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
